<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Advanced Real-time Object, Pose, Face, Behavior, QR Code Detection System</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f0f0f0;
        }

        .container {
            max-width: 800px;
            margin: 0 auto;
        }

        h1 {
            text-align: center;
            color: #333;
        }

        .video-container {
            position: relative;
            width: 100%;
            max-width: 640px;
            margin: 0 auto;
            aspect-ratio: 4 / 3;
            background-color: #000;
        }

        #video, #canvas, #placeholder-canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: contain;
        }

        .controls {
            display: flex;
            justify-content: center;
            margin-top: 20px;
            gap: 10px;
            flex-wrap: wrap;
        }

        button {
            padding: 10px 20px;
            font-size: 16px;
            cursor: pointer;
            background-color: #4CAF50;
            color: white;
            border: none;
            border-radius: 5px;
            transition: background-color 0.3s ease;
        }

        button:hover {
            background-color: #45a049;
        }

        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }

        #total_obj, #detectionResults, #log, #nlpDescription, #qrResult {
            margin-top: 20px;
            padding: 10px;
            background-color: white;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }

        #total_obj {
            font-size: 18px;
            font-weight: bold;
            text-align: center;
        }

        #log, #nlpDescription {
            position: relative;
            white-space: pre-wrap;
            font-family: monospace;
            font-size: 14px;
            overflow-y: auto;
            padding-bottom: 30px;
            max-height: 200px;
        }

        .expand-btn {
            position: absolute;
            bottom: 5px;
            right: 5px;
            background-color: rgba(0, 0, 0, 0.5);
            color: white;
            border: none;
            padding: 5px 10px;
            cursor: pointer;
            font-size: 12px;
            border-radius: 3px;
            z-index: 10;
        }

        .expanded {
            max-height: none !important;
        }

        .log-container {
            position: relative;
        }

        .log-content {
            overflow-y: auto;
        }

        .qr-overlay {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 200px;
            height: 200px;
            border: 2px solid #4CAF50;
            display: none;
            z-index: 100;
        }

        #qrResult {
            font-size: 16px;
            line-height: 1.5;
        }

        #qrResult.success {
            border-left: 4px solid #4CAF50;
        }

        #qrResult.error {
            border-left: 4px solid #f44336;
        }

        .scanning-indicator {
            position: absolute;
            top: 10px;
            left: 50%;
            transform: translateX(-50%);
            background-color: rgba(0, 0, 0, 0.7);
            color: white;
            padding: 5px 10px;
            border-radius: 15px;
            font-size: 14px;
            z-index: 101;
            display: none;
        }

        @media (max-width: 600px) {
            .controls {
                flex-direction: column;
                align-items: stretch;
            }

            button {
                width: 100%;
            }

            .video-container {
                max-width: 100%;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Advanced Real-time Object, Pose, Face, Behavior, and QR Code Detection</h1>
        <div class="video-container">
            <video id="video" playsinline></video>
            <canvas id="canvas"></canvas>
            <canvas id="placeholder-canvas"></canvas>
            <div id="qrOverlay" class="qr-overlay"></div>
            <div id="scanningIndicator" class="scanning-indicator">Scanning QR Code...</div>
        </div>
        <div class="controls">
            <button id="toggleCamera">Start Camera</button>
            <button id="switchCamera">Switch Camera</button>
            <button id="startDetection">Start Detection</button>
            <button id="scanQR">Scan QR Code</button>
        </div>
        <div id="total_obj">Total Detected <span id="obj_count">0</span> objects</div>
        <div id="qrResult"></div>
        <div id="detectionResults"></div>
        <div id="nlpDescription" class="log-container">
            <div class="log-content"></div>
            <button class="expand-btn">Expand</button>
        </div>
        <div id="log" class="log-container">
            <div class="log-content"></div>
            <button class="expand-btn">Expand</button>
        </div>
    </div>

    <!-- Core Libraries -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>
    <script src="https://cdn.jsdelivr.net/npm/simple-statistics@7.8.0/dist/simple-statistics.min.js"></script>
    <script src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady();" async></script>
    <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/html5-qrcode/html5-qrcode.min.js"></script>

    <script>
        let offscreenCanvas, offscreenCtx;
        // All existing variables and state management
        let video, canvas, ctx, placeholderCanvas, placeholderCtx, objectDetectionModel, poseNetModel, stream;
        let isDetecting = false;
        let isScanning = false;
        let currentCameraFacingMode = 'environment';
        let html5QrcodeScanner = null;
        const objCountSpan = document.getElementById('obj_count');
        const nlpDescriptionDiv = document.getElementById('nlpDescription');
        const qrResult = document.getElementById('qrResult');
        const qrOverlay = document.getElementById('qrOverlay');
        const scanningIndicator = document.getElementById('scanningIndicator');
        let uniqueObjects = new Set();
        let prevObjects = [];
        let objectTracker = {};
        let gestureHistory = [];
        let motionHistory = [];
        let speedHistory = {};
        let behaviorHistory = [];
        let positionHistory = [];
        let restrictedAreas = [
            { x: 100, y: 100, width: 200, height: 150 },
            { x: 400, y: 300, width: 150, height: 100 }
        ];

        // UI Elements
        const toggleCameraButton = document.getElementById('toggleCamera');
        const switchCameraButton = document.getElementById('switchCamera');
        const startDetectionButton = document.getElementById('startDetection');
        const scanQRButton = document.getElementById('scanQR');
        const detectionResultsDiv = document.getElementById('detectionResults');
        const logDiv = document.getElementById('log');

        // Logging function
        function log(message) {
            console.log(message);
            const logEntry = document.createElement('div');
            logEntry.textContent = `${new Date().toLocaleTimeString()}: ${message}`;
            document.querySelector('#log .log-content').insertBefore(logEntry, document.querySelector('#log .log-content').firstChild);
            if (document.querySelector('#log .log-content').childElementCount > 50) {
                document.querySelector('#log .log-content').removeChild(document.querySelector('#log .log-content').lastChild);
            }
        }

        // QR Code Scanning Functions
        async function toggleQRScanning() {
            if (isScanning) {
                await stopQRScanning();
            } else {
                await startQRScanning();
            }
        }

        async function startQRScanning() {
            if (!stream) return;
            
            isScanning = true;
            isDetecting = false;
            startDetectionButton.textContent = 'Start Detection';
            scanQRButton.textContent = 'Stop Scanning';
            qrOverlay.style.display = 'block';
            scanningIndicator.style.display = 'block';
            qrResult.textContent = '';
            qrResult.className = '';

            if (html5QrcodeScanner) {
                await html5QrcodeScanner.clear();
            }

            html5QrcodeScanner = new Html5Qrcode("qrOverlay");
            
            try {
                await html5QrcodeScanner.start(
                    { facingMode: currentCameraFacingMode },
                    {
                        fps: 10,
                        qrbox: { width: 250, height: 250 },
                        aspectRatio: 1.0
                    },
                    (decodedText, decodedResult) => {
                        qrResult.textContent = `QR Code Detected: ${decodedText}`;
                        qrResult.className = 'success';
                        log(`QR Code detected: ${decodedText}`);
                        // Vibrate if supported
                        if (navigator.vibrate) {
                            navigator.vibrate(200);
                        }
                    },
                    (errorMessage) => {
                        // Handle errors silently to avoid console spam
                    }
                );
            } catch (err) {
                qrResult.textContent = `Error starting QR scanner: ${err.message}`;
                qrResult.className = 'error';
                log('QR Scanner error: ' + err.message);
                await stopQRScanning();
            }
        }

        async function stopQRScanning() {
            if (html5QrcodeScanner) {
                try {
                    await html5QrcodeScanner.stop();
                    await html5QrcodeScanner.clear();
                    html5QrcodeScanner = null;
                } catch (err) {
                    console.error('Error stopping QR scanner:', err);
                }
            }
            
            isScanning = false;
            scanQRButton.textContent = 'Scan QR Code';
            qrOverlay.style.display = 'none';
            scanningIndicator.style.display = 'none';
        }

        // Camera Control Functions
        async function toggleCamera() {
            if (stream) {
                stopCamera();
            } else {
                await startCamera();
            }
        }

        async function startCamera() {
            let retryCount = 0;
            const maxRetries = 3;

            while (retryCount < maxRetries) {
                try {
                    const constraints = {
                        video: {
                            facingMode: currentCameraFacingMode,
                            width: { ideal: 640 },
                            height: { ideal: 480 }
                        }
                    };

                    stream = await navigator.mediaDevices.getUserMedia(constraints);
                    video.srcObject = stream;
                    await video.play();

                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    placeholderCanvas.width = video.videoWidth;
                    placeholderCanvas.height = video.videoHeight;
                    log(`Video dimensions: ${video.videoWidth}x${video.videoHeight}`);

                    // Create offscreen canvas for better performance
                    offscreenCanvas = new OffscreenCanvas(video.videoWidth, video.videoHeight);
                    offscreenCtx = offscreenCanvas.getContext('2d');

                    toggleCameraButton.textContent = 'Stop Camera';
                    switchCameraButton.disabled = false;
                    startDetectionButton.disabled = false;
                    scanQRButton.disabled = false;
                    video.style.display = 'block';
                    canvas.style.display = 'block';
                    placeholderCanvas.style.display = 'none';
                    return; // Success
                } catch (error) {
                    retryCount++;
                    log(`Camera start attempt ${retryCount} failed: ${error.message}`);
                    await new Promise(resolve => setTimeout(resolve, 1000));
                }
            }
            
            alert('Unable to start camera after multiple attempts. Please check camera permissions and refresh the page.');
        }

        function stopCamera() {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
                video.srcObject = null;
                toggleCameraButton.textContent = 'Start Camera';
                switchCameraButton.disabled = true;
                startDetectionButton.disabled = true;
                scanQRButton.disabled = true;
                video.style.display = 'none';
                canvas.style.display = 'none';
                placeholderCanvas.style.display = 'block';
                placeholderCtx.drawImage(canvas, 0, 0);
                
                if (isScanning) {
                    stopQRScanning();
                }
                
                log('Camera stopped');
            }
        }

        async function switchCamera() {
            currentCameraFacingMode = currentCameraFacingMode === 'environment' ? 'user' : 'environment';
            if (stream) {
                const isScanning = html5QrcodeScanner !== null;
                if (isScanning) {
                    await stopQRScanning();
                }
                stopCamera();
                await startCamera();
                if (isScanning) {
                    await startQRScanning();
                }
            }
            log(`Switched to ${currentCameraFacingMode} camera`);
        }

        // Initialize video elements
        video = document.getElementById('video');
        canvas = document.getElementById('canvas');
        ctx = canvas.getContext('2d');
        placeholderCanvas = document.getElementById('placeholder-canvas');
        placeholderCtx = placeholderCanvas.getContext('2d');

        // Event listeners
        toggleCameraButton.addEventListener('click', toggleCamera);
        switchCameraButton.addEventListener('click', switchCamera);
        startDetectionButton.addEventListener('click', startDetection);
        scanQRButton.addEventListener('click', toggleQRScanning);

        // Initialize button states
        switchCameraButton.disabled = true;
        startDetectionButton.disabled = true;
        scanQRButton.disabled = true;

        // Expand functionality for log and nlpDescription
        document.querySelectorAll('.expand-btn').forEach(btn => {
            btn.addEventListener('click', function() {
                const parentDiv = this.closest('.log-container');
                parentDiv.classList.toggle('expanded');
                this.textContent = parentDiv.classList.contains('expanded') ? 'Collapse' : 'Expand';
            });
        });

        // Load OpenCV.js
        function onOpenCvReady() {
            log('OpenCV.js is ready');
            loadModels();
        }

        // Model Loading
        const timeout = 30000; // 30 second timeout
        const loadWithTimeout = async (promise, modelName) => {
            try {
                await Promise.race([
                    promise,
                    new Promise((_, reject) => 
                        setTimeout(() => reject(new Error(`${modelName} loading timed out`)), timeout)
                    )
                ]);
                log(`${modelName} loaded successfully`);
            } catch (error) {
                log(`Error loading ${modelName}: ${error.message}`);
                throw error;
            }
        };

        async function loadModels() {
            try {
                log('Loading COCO-SSD model...');
                await loadWithTimeout(cocoSsd.load(), 'COCO-SSD model');
                objectDetectionModel = await cocoSsd.load();

                log('Loading PoseNet model...');
                await loadWithTimeout(posenet.load(), 'PoseNet model');
                poseNetModel = await posenet.load();

                // Continue with face-api.js models...
                log('Loading Face-API.js models...');
                const modelPath = 'https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js/weights/';
                
                await Promise.all([
                    loadWithTimeout(faceapi.nets.ssdMobilenetv1.loadFromUri(modelPath), 'Face Detection'),
                    loadWithTimeout(faceapi.nets.faceLandmark68Net.loadFromUri(modelPath), 'Face Landmark'),
                    loadWithTimeout(faceapi.nets.faceRecognitionNet.loadFromUri(modelPath), 'Face Recognition'),
                    loadWithTimeout(faceapi.nets.faceExpressionNet.loadFromUri(modelPath), 'Face Expression'),
                    loadWithTimeout(faceapi.nets.ageGenderNet.loadFromUri(modelPath), 'Age and Gender')
                ]);

                log('All models loaded successfully');
            } catch (error) {
                log('Critical error loading models: ' + error.message);
                alert('Error loading required models. Please refresh the page and try again.');
            }
        }

        // Detection Functions
        async function startDetection() {
            if (!objectDetectionModel || !poseNetModel) {
                await loadModels();
            }

            if (isScanning) {
                await stopQRScanning();
            }

            isDetecting = !isDetecting;
            startDetectionButton.textContent = isDetecting ? 'Stop Detection' : 'Start Detection';

            if (isDetecting) {
                log('Object, pose, face, behavior, and statistical anomaly detection started');
                detectAll();
            } else {
                log('Object, pose, face, behavior, and statistical anomaly detection stopped');
            }
        }

        async function detectAll() {
            if (!isDetecting) return;

            let mat = null;
            try {
                offscreenCtx.drawImage(video, 0, 0, offscreenCanvas.width, offscreenCanvas.height);
                const imageData = offscreenCtx.getImageData(0, 0, offscreenCanvas.width, offscreenCanvas.height);
                mat = cv.matFromImageData(imageData);

                // Limit detection frequency
                await new Promise(resolve => setTimeout(resolve, 100)); // Add 100ms delay

                const objectPredictions = await objectDetectionModel.detect(offscreenCanvas);
                const poses = await poseNetModel.estimateMultiplePoses(offscreenCanvas, {
                    maxDetections: 5, // Limit max detections
                    scoreThreshold: 0.5,
                    nmsRadius: 20
                });
                const motions = debouncedDetectMotion(mat, objectPredictions);
                const anomalies = detectStatisticalAnomalies(motions);
                const faceResults = await detectFaces(offscreenCanvas);
                const behaviors = analyzeBehavior(poses);

                log(`Detected ${objectPredictions.length} objects, ${poses.length} poses, ${motions.length} motions, ${anomalies.length} anomalies, ${faceResults.length} faces, and ${behaviors.length} behaviors`);

                objectPredictions.forEach(prediction => {
                    uniqueObjects.add(prediction.class);
                });
                updateObjectCount();

                let detectionText = '';
                objectPredictions.forEach((prediction, index) => {
                    const [x, y, width, height] = prediction.bbox;
                    const color = [255, 0, 0, 255]; // Red color for object bounding box

                    const point1 = new cv.Point(x, y);
                    const point2 = new cv.Point(x + width, y + height);
                    cv.rectangle(mat, point1, point2, color, 2);

                    const text = `${prediction.class} (${Math.round(prediction.score * 100)}%)`;
                    const org = new cv.Point(x, y - 5);
                    cv.putText(mat, text, org, cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 1);

                    detectionText += `${index + 1}. ${text} at (${Math.round(x)}, ${Math.round(y)})\n`;
                });

                // Draw pose keypoints and skeletons
                poses.forEach((pose, index) => {
                    const color = [0, 255, 0, 255]; // Green color for pose
                    pose.keypoints.forEach(keypoint => {
                        if (keypoint.score > 0.2) {
                            const { y, x } = keypoint.position;
                            cv.circle(mat, new cv.Point(x, y), 5, color, -1);
                        }
                    });

                    // Draw skeleton
                    const adjacentKeyPoints = posenet.getAdjacentKeyPoints(pose.keypoints, 0.2);
                    adjacentKeyPoints.forEach(keypoints => {
                        cv.line(mat, 
                            new cv.Point(keypoints[0].position.x, keypoints[0].position.y),
                            new cv.Point(keypoints[1].position.x, keypoints[1].position.y),
                            color, 2);
                    });

                    detectionText += `Person ${index + 1} detected with ${pose.keypoints.length} keypoints\n`;
                    detectionText += `Behavior: ${behaviors[index]}\n`;
                });

                // Draw restricted areas
                restrictedAreas.forEach((area, index) => {
                    cv.rectangle(mat, 
                        new cv.Point(area.x, area.y),
                        new cv.Point(area.x + area.width, area.y + area.height),
                        [255, 255, 0, 255], 2); // Yellow color for restricted areas
                    cv.putText(mat, `Restricted Area ${index + 1}`, 
                        new cv.Point(area.x, area.y - 5),
                        cv.FONT_HERSHEY_SIMPLEX, 0.5, [255, 255, 0, 255], 1);
                });

                // Draw face detection results
                faceResults.forEach((detection, index) => {
                    const { detection: { box }, age, gender, expressions } = detection;
                    const { x, y, width, height } = box;
                    const color = [0, 0, 255, 255]; // Blue color for face bounding box

                    cv.rectangle(mat, new cv.Point(x, y), new cv.Point(x + width, y + height), color, 2);

                    const text = `Face ${index + 1}: ${Math.round(age)}y ${gender}`;
                    cv.putText(mat, text, new cv.Point(x, y - 5), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 1);

                    detectionText += `${text}\n`;
                });

                cv.imshow(canvas, mat);
                detectionResultsDiv.textContent = detectionText;

                const nlpDescription = generateNLPDescription(objectPredictions, poses, anomalies, motions, faceResults, behaviors);
                if (nlpDescription) {
                    const descriptionElement = document.createElement('p');
                    descriptionElement.textContent = `${new Date().toLocaleTimeString()}: ${nlpDescription}`;
                    document.querySelector('#nlpDescription .log-content').insertBefore(descriptionElement, document.querySelector('#nlpDescription .log-content').firstChild);
                    if (document.querySelector('#nlpDescription .log-content').childElementCount > 50) {
                        document.querySelector('#nlpDescription .log-content').removeChild(document.querySelector('#nlpDescription .log-content').lastChild);
                    }
                }
            } catch (error) {
                log('Error during detection: ' + error.message);
                isDetecting = false;
                startDetectionButton.textContent = 'Start Detection';
            } finally {
                if (mat) {
                    mat.delete();
                }
                if (isDetecting) {
                    // Use setTimeout instead of requestAnimationFrame for better control
                    setTimeout(detectAll, 1000 / 30); // Limit to 30 FPS
                }
            }
        }

        // Helper Functions
        function updateObjectCount() {
            objCountSpan.textContent = uniqueObjects.size;
        }

        // Placeholder functions - replace with your actual implementations
        function detectMotion(mat, objectPredictions) {
            // Your motion detection logic here
            return [];
        }

        function detectStatisticalAnomalies(motions) {
            // Your statistical anomaly detection logic here
            return [];
        }

        async function detectFaces(inputVideo) {
            try {
                // Add size options to improve performance
                const options = new faceapi.SsdMobilenetv1Options({ 
                    minConfidence: 0.5,
                    maxResults: 5
                });

                const detections = await faceapi.detectAllFaces(inputVideo, options)
                    .withFaceLandmarks()
                    .withFaceExpressions()
                    .withAgeAndGender();

                return detections;
            } catch (error) {
                log('Error during face detection: ' + error.message);
                return [];
            }
        }

        function analyzeBehavior(poses) {
            // Your behavior analysis logic here
            return poses.map(() => '');
        }

        function generateNLPDescription(objectPredictions, poses, anomalies, motions, faceResults, behaviors) {
            // Your NLP description generation logic here
            return '';
        }

        const debounce = (func, wait) => {
            let timeout;
            return function executedFunction(...args) {
                const later = () => {
                    clearTimeout(timeout);
                    func(...args);
                };
                clearTimeout(timeout);
                timeout = setTimeout(later, wait);
            };
        };

        const debouncedDetectMotion = debounce(detectMotion, 150);

        // Initialize the application
        loadModels();

        window.addEventListener('beforeunload', () => {
            if (stream) {
                stopCamera();
            }
            if (isScanning) {
                stopQRScanning();
            }
            // Clear any remaining OpenCV matrices
            if (motionHistory.length) {
                motionHistory.forEach(mat => {
                    if (mat && !mat.isDeleted) mat.delete();
                });
                motionHistory = [];
            }
        });
    </script>
</body>
</html>

